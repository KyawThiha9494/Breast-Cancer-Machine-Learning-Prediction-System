{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We work with original 30 features and 1 label named “Diagnosis”\n",
    "## Firstly, we import all neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"BreastCancerData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns =[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "564         M        21.56         22.39          142.00     1479.0   \n",
       "565         M        20.13         28.25          131.20     1261.0   \n",
       "566         M        16.60         28.08          108.30      858.1   \n",
       "567         M        20.60         29.33          140.10     1265.0   \n",
       "568         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.replace(to_replace =[\"M\",\"B\"],value=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df1.iloc[:,1:]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df1[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We split 90% for training, 10% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (512, 30) (512,)\n",
      "Test set: (57, 30) (57,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.1,random_state=42)\n",
    "print ('Train set:', x_train.shape,  y_train.shape)\n",
    "print ('Test set:', x_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We fit the scaler on your training data only, then standardise both training and test sets with that scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding: Converting the Labels From Integers to Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add layers to the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(100,input_shape =(30,),activation=\"relu\"))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dense(2,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               3100      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 8,252\n",
      "Trainable params: 8,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the model's structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, to_file='neuralNetwork.png', show_shapes=True, \n",
    "           show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training with 90% for training and 10% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 460 samples, validate on 52 samples\n",
      "Epoch 1/50\n",
      "460/460 [==============================] - 0s 865us/sample - loss: 0.6095 - accuracy: 0.6565 - val_loss: 0.5084 - val_accuracy: 0.8269\n",
      "Epoch 2/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.4572 - accuracy: 0.8587 - val_loss: 0.3948 - val_accuracy: 0.8846\n",
      "Epoch 3/50\n",
      "460/460 [==============================] - 0s 35us/sample - loss: 0.3495 - accuracy: 0.9261 - val_loss: 0.3133 - val_accuracy: 0.8846\n",
      "Epoch 4/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.2736 - accuracy: 0.9391 - val_loss: 0.2555 - val_accuracy: 0.9038\n",
      "Epoch 5/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.2189 - accuracy: 0.9478 - val_loss: 0.2160 - val_accuracy: 0.9038\n",
      "Epoch 6/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.1805 - accuracy: 0.9522 - val_loss: 0.1885 - val_accuracy: 0.9038\n",
      "Epoch 7/50\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.1866 - accuracy: 0.93 - 0s 30us/sample - loss: 0.1530 - accuracy: 0.9630 - val_loss: 0.1681 - val_accuracy: 0.9038\n",
      "Epoch 8/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.1330 - accuracy: 0.9717 - val_loss: 0.1523 - val_accuracy: 0.9231\n",
      "Epoch 9/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.1175 - accuracy: 0.9783 - val_loss: 0.1396 - val_accuracy: 0.9231\n",
      "Epoch 10/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.1059 - accuracy: 0.9804 - val_loss: 0.1295 - val_accuracy: 0.9231\n",
      "Epoch 11/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0966 - accuracy: 0.9826 - val_loss: 0.1212 - val_accuracy: 0.9423\n",
      "Epoch 12/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0898 - accuracy: 0.9826 - val_loss: 0.1145 - val_accuracy: 0.9615\n",
      "Epoch 13/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0837 - accuracy: 0.9826 - val_loss: 0.1091 - val_accuracy: 0.9615\n",
      "Epoch 14/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.0790 - accuracy: 0.9826 - val_loss: 0.1045 - val_accuracy: 0.9615\n",
      "Epoch 15/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0748 - accuracy: 0.9848 - val_loss: 0.1004 - val_accuracy: 0.9615\n",
      "Epoch 16/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0714 - accuracy: 0.9848 - val_loss: 0.0969 - val_accuracy: 0.9615\n",
      "Epoch 17/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.0682 - accuracy: 0.9870 - val_loss: 0.0941 - val_accuracy: 0.9615\n",
      "Epoch 18/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0656 - accuracy: 0.9870 - val_loss: 0.0916 - val_accuracy: 0.9615\n",
      "Epoch 19/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0631 - accuracy: 0.9891 - val_loss: 0.0895 - val_accuracy: 0.9615\n",
      "Epoch 20/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0612 - accuracy: 0.9891 - val_loss: 0.0878 - val_accuracy: 0.9615\n",
      "Epoch 21/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0592 - accuracy: 0.9891 - val_loss: 0.0861 - val_accuracy: 0.9615\n",
      "Epoch 22/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0575 - accuracy: 0.9891 - val_loss: 0.0846 - val_accuracy: 0.9615\n",
      "Epoch 23/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.0557 - accuracy: 0.9891 - val_loss: 0.0830 - val_accuracy: 0.9615\n",
      "Epoch 24/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0542 - accuracy: 0.9891 - val_loss: 0.0813 - val_accuracy: 0.9808\n",
      "Epoch 25/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0529 - accuracy: 0.9891 - val_loss: 0.0799 - val_accuracy: 0.9808\n",
      "Epoch 26/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.0515 - accuracy: 0.9891 - val_loss: 0.0788 - val_accuracy: 0.9808\n",
      "Epoch 27/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0501 - accuracy: 0.9891 - val_loss: 0.0779 - val_accuracy: 0.9808\n",
      "Epoch 28/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0490 - accuracy: 0.9891 - val_loss: 0.0771 - val_accuracy: 0.9808\n",
      "Epoch 29/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0478 - accuracy: 0.9891 - val_loss: 0.0762 - val_accuracy: 0.9808\n",
      "Epoch 30/50\n",
      "460/460 [==============================] - 0s 24us/sample - loss: 0.0467 - accuracy: 0.9913 - val_loss: 0.0753 - val_accuracy: 0.9808\n",
      "Epoch 31/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0456 - accuracy: 0.9913 - val_loss: 0.0743 - val_accuracy: 0.9808\n",
      "Epoch 32/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0447 - accuracy: 0.9891 - val_loss: 0.0735 - val_accuracy: 0.9808\n",
      "Epoch 33/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0436 - accuracy: 0.9913 - val_loss: 0.0729 - val_accuracy: 0.9808\n",
      "Epoch 34/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.0427 - accuracy: 0.9913 - val_loss: 0.0724 - val_accuracy: 0.9808\n",
      "Epoch 35/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0419 - accuracy: 0.9913 - val_loss: 0.0716 - val_accuracy: 0.9808\n",
      "Epoch 36/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.0409 - accuracy: 0.9913 - val_loss: 0.0712 - val_accuracy: 0.9808\n",
      "Epoch 37/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0401 - accuracy: 0.9913 - val_loss: 0.0709 - val_accuracy: 0.9808\n",
      "Epoch 38/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0394 - accuracy: 0.9913 - val_loss: 0.0706 - val_accuracy: 0.9808\n",
      "Epoch 39/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.0383 - accuracy: 0.9935 - val_loss: 0.0699 - val_accuracy: 0.9808\n",
      "Epoch 40/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0376 - accuracy: 0.9935 - val_loss: 0.0696 - val_accuracy: 0.9808\n",
      "Epoch 41/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0367 - accuracy: 0.9935 - val_loss: 0.0693 - val_accuracy: 0.9808\n",
      "Epoch 42/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0359 - accuracy: 0.9935 - val_loss: 0.0690 - val_accuracy: 0.9808\n",
      "Epoch 43/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0352 - accuracy: 0.9935 - val_loss: 0.0684 - val_accuracy: 0.9808\n",
      "Epoch 44/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0343 - accuracy: 0.9935 - val_loss: 0.0678 - val_accuracy: 0.9808\n",
      "Epoch 45/50\n",
      "460/460 [==============================] - 0s 29us/sample - loss: 0.0335 - accuracy: 0.9935 - val_loss: 0.0673 - val_accuracy: 0.9808\n",
      "Epoch 46/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0328 - accuracy: 0.9935 - val_loss: 0.0669 - val_accuracy: 0.9808\n",
      "Epoch 47/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0323 - accuracy: 0.9935 - val_loss: 0.0663 - val_accuracy: 0.9808\n",
      "Epoch 48/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0313 - accuracy: 0.9935 - val_loss: 0.0666 - val_accuracy: 0.9808\n",
      "Epoch 49/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0305 - accuracy: 0.9935 - val_loss: 0.0665 - val_accuracy: 0.9808\n",
      "Epoch 50/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0299 - accuracy: 0.9935 - val_loss: 0.0666 - val_accuracy: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1746be74888>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=50, batch_size=100,validation_split=0.1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Loss and Accuracy of the neural model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 52us/sample - loss: 0.0894 - accuracy: 0.9825\n",
      "Loss =  0.0894215926527977 Accuracy =  0.98245615\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, batch_size=100)\n",
    "print(\"Loss = \" ,loss, \"Accuracy = \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:  [1. 0.] , Predicted: [0.95990884 0.0400911 ]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [6.4606476e-04 9.9935395e-01]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.00172552 0.99827445]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.993672e-01 6.328802e-04]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.9962294e-01 3.7699513e-04]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [2.9765264e-04 9.9970227e-01]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [3.2104301e-04 9.9967897e-01]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.03899173 0.9610082 ]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.6690027  0.33099735]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.99875414 0.00124588]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.89879715 0.10120286]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.01789909 0.9821009 ]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9880945  0.01190552]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.03237764 0.9676223 ]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.991499e-01 8.500795e-04]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.00484487 0.9951551 ]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9986608  0.00133924]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.9960452e-01 3.9554486e-04]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.9984407e-01 1.5586743e-04]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [4.1217956e-04 9.9958783e-01]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.97850686 0.02149319]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9910862  0.00891384]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [3.1155482e-04 9.9968851e-01]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.9950385e-01 4.9618020e-04]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9979693  0.00203063]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.9902403e-01 9.7594946e-04]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.9917382e-01 8.2614657e-04]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9977552  0.00224482]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9976012  0.00239876]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [4.2768833e-04 9.9957234e-01]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9987809  0.00121913]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.9958640e-01 4.1360167e-04]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.996505   0.00349506]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9973278 0.0026722]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.9956101e-01 4.3892354e-04]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9984127 0.0015872]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.04500564 0.9549943 ]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.99796057 0.00203945]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [7.6743867e-04 9.9923253e-01]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.94920385 0.05079615]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.9926108e-01 7.3895894e-04]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.00226198 0.997738  ]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9989573  0.00104273]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.9903095e-01 9.6907082e-04]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.932789   0.06721102]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.99070084 0.00929908]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.9960512e-01 3.9486046e-04]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.99687696 0.00312299]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.97655576 0.02344421]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.992440e-01 7.561014e-04]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [7.2309130e-04 9.9927694e-01]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [3.3941018e-04 9.9966061e-01]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.7920822  0.20791788]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.89402205 0.10597792]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.9980730e-01 1.9269546e-04]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.996651   0.00334904]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [9.9972063e-01 2.7932809e-04]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "for i in np.arange(len(predictions)):\n",
    "    print(print(\"Actual: \" , y_test[i],\", Predicted:\" , predictions[i]))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with 16 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = df1[['texture_mean', 'area_mean', 'smoothness_mean','concavity_mean',\n",
    "       'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'texture_se', 'area_se', 'smoothness_se',\n",
    "       'concavity_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'smoothness_worst',\n",
    "       'concavity_worst', 'symmetry_worst', 'fractal_dimension_worst']]\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=df1[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We split 90% for training, 10% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (512, 16) (512,)\n",
      "Test set: (57, 16) (57,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x1_train,x1_test,y1_train,y1_test = train_test_split(x1,y1,test_size=0.1,random_state=42)\n",
    "print ('Train set:', x1_train.shape,  y1_train.shape)\n",
    "print ('Test set:', x1_test.shape,  y1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We fit the scaler on your training data only, then standardise both training and test sets with that scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x1_train = sc.fit_transform(x1_train)\n",
    "x1_test = sc.transform(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding: Converting the Labels From Integers to Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train = to_categorical(y1_train)\n",
    "y1_test = to_categorical(y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add layers to the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(Dense(100,input_shape =(16,),activation=\"relu\"))\n",
    "model1.add(Dense(50,activation=\"sigmoid\"))\n",
    "model1.add(Dense(2,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               1700      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 6,852\n",
      "Trainable params: 6,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with 90% for training and 10% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 460 samples, validate on 52 samples\n",
      "Epoch 1/50\n",
      "460/460 [==============================] - 0s 837us/sample - loss: 1.0143 - accuracy: 0.3870 - val_loss: 0.8991 - val_accuracy: 0.3269\n",
      "Epoch 2/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.8123 - accuracy: 0.3891 - val_loss: 0.6984 - val_accuracy: 0.4615\n",
      "Epoch 3/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.6563 - accuracy: 0.5326 - val_loss: 0.5576 - val_accuracy: 0.8077\n",
      "Epoch 4/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.5451 - accuracy: 0.8174 - val_loss: 0.4673 - val_accuracy: 0.8269\n",
      "Epoch 5/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.4697 - accuracy: 0.8957 - val_loss: 0.4096 - val_accuracy: 0.9231\n",
      "Epoch 6/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.4133 - accuracy: 0.9109 - val_loss: 0.3704 - val_accuracy: 0.9038\n",
      "Epoch 7/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.3704 - accuracy: 0.9239 - val_loss: 0.3407 - val_accuracy: 0.8846\n",
      "Epoch 8/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.3335 - accuracy: 0.9174 - val_loss: 0.3161 - val_accuracy: 0.8846\n",
      "Epoch 9/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.3010 - accuracy: 0.9239 - val_loss: 0.2951 - val_accuracy: 0.8846\n",
      "Epoch 10/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.2729 - accuracy: 0.9304 - val_loss: 0.2765 - val_accuracy: 0.9038\n",
      "Epoch 11/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.2482 - accuracy: 0.9413 - val_loss: 0.2594 - val_accuracy: 0.9038\n",
      "Epoch 12/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.2269 - accuracy: 0.9500 - val_loss: 0.2443 - val_accuracy: 0.9038\n",
      "Epoch 13/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.2082 - accuracy: 0.9587 - val_loss: 0.2302 - val_accuracy: 0.9038\n",
      "Epoch 14/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.1915 - accuracy: 0.9674 - val_loss: 0.2176 - val_accuracy: 0.9038\n",
      "Epoch 15/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.1770 - accuracy: 0.9696 - val_loss: 0.2064 - val_accuracy: 0.9038\n",
      "Epoch 16/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.1639 - accuracy: 0.9717 - val_loss: 0.1966 - val_accuracy: 0.9038\n",
      "Epoch 17/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.1526 - accuracy: 0.9717 - val_loss: 0.1878 - val_accuracy: 0.9038\n",
      "Epoch 18/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.1427 - accuracy: 0.9739 - val_loss: 0.1801 - val_accuracy: 0.9038\n",
      "Epoch 19/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.1338 - accuracy: 0.9739 - val_loss: 0.1732 - val_accuracy: 0.9231\n",
      "Epoch 20/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.1256 - accuracy: 0.9761 - val_loss: 0.1673 - val_accuracy: 0.9231\n",
      "Epoch 21/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.1185 - accuracy: 0.9783 - val_loss: 0.1619 - val_accuracy: 0.9423\n",
      "Epoch 22/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.1119 - accuracy: 0.9804 - val_loss: 0.1569 - val_accuracy: 0.9423\n",
      "Epoch 23/50\n",
      "460/460 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.97 - 0s 28us/sample - loss: 0.1066 - accuracy: 0.9804 - val_loss: 0.1521 - val_accuracy: 0.9423\n",
      "Epoch 24/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.1012 - accuracy: 0.9804 - val_loss: 0.1479 - val_accuracy: 0.9423\n",
      "Epoch 25/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0962 - accuracy: 0.9804 - val_loss: 0.1442 - val_accuracy: 0.9423\n",
      "Epoch 26/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.0919 - accuracy: 0.9826 - val_loss: 0.1407 - val_accuracy: 0.9423\n",
      "Epoch 27/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.0880 - accuracy: 0.9826 - val_loss: 0.1376 - val_accuracy: 0.9423\n",
      "Epoch 28/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0847 - accuracy: 0.9826 - val_loss: 0.1348 - val_accuracy: 0.9423\n",
      "Epoch 29/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0812 - accuracy: 0.9826 - val_loss: 0.1321 - val_accuracy: 0.9423\n",
      "Epoch 30/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0783 - accuracy: 0.9826 - val_loss: 0.1296 - val_accuracy: 0.9423\n",
      "Epoch 31/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0755 - accuracy: 0.9848 - val_loss: 0.1270 - val_accuracy: 0.9423\n",
      "Epoch 32/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0732 - accuracy: 0.9870 - val_loss: 0.1249 - val_accuracy: 0.9423\n",
      "Epoch 33/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0710 - accuracy: 0.9870 - val_loss: 0.1226 - val_accuracy: 0.9423\n",
      "Epoch 34/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0689 - accuracy: 0.9870 - val_loss: 0.1206 - val_accuracy: 0.9423\n",
      "Epoch 35/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0670 - accuracy: 0.9870 - val_loss: 0.1187 - val_accuracy: 0.9423\n",
      "Epoch 36/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.0652 - accuracy: 0.9870 - val_loss: 0.1170 - val_accuracy: 0.9423\n",
      "Epoch 37/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0636 - accuracy: 0.9870 - val_loss: 0.1154 - val_accuracy: 0.9423\n",
      "Epoch 38/50\n",
      "460/460 [==============================] - 0s 30us/sample - loss: 0.0623 - accuracy: 0.9870 - val_loss: 0.1141 - val_accuracy: 0.9423\n",
      "Epoch 39/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0608 - accuracy: 0.9891 - val_loss: 0.1129 - val_accuracy: 0.9423\n",
      "Epoch 40/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0595 - accuracy: 0.9891 - val_loss: 0.1116 - val_accuracy: 0.9423\n",
      "Epoch 41/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0583 - accuracy: 0.9891 - val_loss: 0.1103 - val_accuracy: 0.9423\n",
      "Epoch 42/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0571 - accuracy: 0.9891 - val_loss: 0.1091 - val_accuracy: 0.9423\n",
      "Epoch 43/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0561 - accuracy: 0.9891 - val_loss: 0.1078 - val_accuracy: 0.9423\n",
      "Epoch 44/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0551 - accuracy: 0.9891 - val_loss: 0.1068 - val_accuracy: 0.9423\n",
      "Epoch 45/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0541 - accuracy: 0.9891 - val_loss: 0.1061 - val_accuracy: 0.9423\n",
      "Epoch 46/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0531 - accuracy: 0.9891 - val_loss: 0.1052 - val_accuracy: 0.9423\n",
      "Epoch 47/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0522 - accuracy: 0.9870 - val_loss: 0.1042 - val_accuracy: 0.9423\n",
      "Epoch 48/50\n",
      "460/460 [==============================] - 0s 26us/sample - loss: 0.0514 - accuracy: 0.9891 - val_loss: 0.1030 - val_accuracy: 0.9423\n",
      "Epoch 49/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0506 - accuracy: 0.9891 - val_loss: 0.1020 - val_accuracy: 0.9423\n",
      "Epoch 50/50\n",
      "460/460 [==============================] - 0s 28us/sample - loss: 0.0498 - accuracy: 0.9870 - val_loss: 0.1013 - val_accuracy: 0.9423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1746d88da88>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x1_train, y1_train, epochs=50, batch_size=100,validation_split=0.1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Loss and Accuracy of the neural model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 52us/sample - loss: 0.1148 - accuracy: 0.9825\n",
      "Loss =  0.1147887334227562 Accuracy =  0.98245615\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model1.evaluate(x1_test, y1_test, batch_size=100)\n",
    "print(\"Loss = \" ,loss, \"Accuracy = \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:  [1. 0.] , Predicted: [0.90762866 0.09237137]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.00486355 0.99513644]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.00633942 0.9936606 ]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9931323  0.00686772]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9969212 0.0030788]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.00126945 0.9987306 ]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.00147325 0.9985267 ]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.39952004 0.60047996]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.63182354 0.36817646]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9931678  0.00683221]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.7785531  0.22144683]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.08812931 0.9118707 ]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9597538  0.04024621]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.02571172 0.9742882 ]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9950867  0.00491326]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.03978762 0.96021235]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9937896  0.00621034]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9973489  0.00265106]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9984805  0.00151946]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.00191545 0.99808455]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.9668797  0.03312029]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.98229235 0.01770759]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.00134222 0.9986578 ]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9967223  0.00327768]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9925069  0.00749309]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.99727976 0.00272019]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.99136823 0.00863176]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9745421  0.02545794]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9886902  0.01130987]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.00211518 0.9978848 ]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9866794  0.01332061]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9973133  0.00268662]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.99633104 0.00366895]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9912122  0.00878784]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9971322  0.00286782]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.99489695 0.00510305]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.37767726 0.62232274]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9976968  0.00230313]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.00417571 0.99582434]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.89688814 0.10311186]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9952819  0.00471809]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.01663896 0.98336107]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9915679  0.00843211]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.99235207 0.00764798]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.98696554 0.0130345 ]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.94934434 0.05065567]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9978016  0.00219841]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.99602    0.00397997]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.87189436 0.12810564]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9920689  0.00793116]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.00332156 0.9966785 ]\n",
      "None\n",
      "Actual:  [0. 1.] , Predicted: [0.00151693 0.9984831 ]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.5853719  0.41462806]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9567034  0.04329662]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9981629  0.00183704]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.9795242  0.02047582]\n",
      "None\n",
      "Actual:  [1. 0.] , Predicted: [0.99713194 0.00286798]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "predictions = model1.predict(x1_test)\n",
    "for i in np.arange(len(predictions)):\n",
    "    print(print(\"Actual: \" , y1_test[i],\", Predicted:\" , predictions[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "#### The Neural NetWork Model has good prediction with accruracy score around 98% but takes more time than other model to train the data.  Furthermore, after applying feature selection with 16 features, the model still yields a good prediction with the same accuracy score = 0.9825 compared with 30 features, yet the loss is slightly higher than the loss with original 30 features (0.1148 and 0.0894)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
